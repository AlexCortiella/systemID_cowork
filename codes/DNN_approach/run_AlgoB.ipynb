{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = './dnn/Xtrue_hl4_node16_batch100_ep200_tanh.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b4cc94b3e285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;31m# Model[mc], Min_prev[mc], Max_prev[mc] = dnn_train_keras(Train[mc], Ar[mc], Opt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mAr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mMin_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMax_prev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'write'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = './dnn/Xtrue_hl4_node16_batch100_ep200_tanh.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import numpy.linalg as LA\n",
    "# import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import rc\n",
    "rc('font', **{'family':'Times', 'size':13})\n",
    "# rc('text', usetex=True)\n",
    "rc('savefig', **{'transparent':False})\n",
    "from colorama import init, Fore, Back, Style\n",
    "init(autoreset=True)\n",
    "\n",
    "\n",
    "import os, sys\n",
    "sys.path.append('./util/')\n",
    "from DNN_basic_utils import *\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics import r2_score\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, LeakyReLU, PReLU\n",
    "from keras import losses, initializers, optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from matplotlib import cm\n",
    "# from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "# from scipy.linalg import lstsq\n",
    "\n",
    "# ####### SPGL1 package #######\n",
    "# from spgl1 import spg_bpdn\n",
    "# from spgl1.lsqr import lsqr\n",
    "# from spgl1 import spgl1, spg_lasso, spg_bp, spg_bpdn, spg_mmv\n",
    "# from spgl1.spgl1 import norm_l1nn_primal, norm_l1nn_dual, norm_l1nn_project\n",
    "# from spgl1.spgl1 import norm_l12nn_primal, norm_l12nn_dual, norm_l12nn_project\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def multi_index(poly_order, dim):\n",
    "\tPoly = PolynomialFeatures(degree=poly_order)\n",
    "\tx = np.zeros((2, dim))\n",
    "\tPoly.fit_transform(x)\n",
    "\n",
    "\tindex = Poly.powers_\n",
    "\tP = index.shape[0]\n",
    "\treturn index, P\n",
    "\n",
    "\n",
    "def Phi_ft(x, poly_order):\n",
    "\tx = np.array(x)\n",
    "\tnx = x.shape[0]\n",
    "\tdim = x.shape[1]\n",
    "\n",
    "\tAlpha, P = multi_index(poly_order, dim) ## multi-index \n",
    "\n",
    "\tphi_mat = np.zeros((P, nx))\n",
    "\tfor pi in range(P):\n",
    "\t\tval = np.array([x[:,j]**Alpha[pi][j] for j in range(dim)])\n",
    "\t\tphi_mat[pi] = np.prod(val, axis=0)\n",
    "\t\n",
    "\tphi_mat = phi_mat.T\n",
    "\n",
    "\treturn phi_mat\n",
    "\n",
    "#####################################################################################\n",
    "class Obj():\n",
    "\tdef __init__(self):\n",
    "\t\treturn\n",
    "\n",
    "class FOLDER():\n",
    "\tdef __init__(self):\n",
    "\t\tself.data = './data/duffling/'\n",
    "\t\tself.dnn = './dnn/'\n",
    "\n",
    "\tdef MakeDir(self):\n",
    "\t\tfor k in self.__dict__.keys():\n",
    "\t\t\tmyfile = self.__dict__[k]\n",
    "\t\t\tif isinstance(myfile, str) == True:\n",
    "\t\t\t\tif not os.path.exists(myfile):\n",
    "\t\t\t\t\tos.makedirs(myfile)\n",
    "\n",
    "Folder = FOLDER()\n",
    "Folder.MakeDir()\n",
    "\n",
    "#####################################################################################\n",
    "##### Dynamic systems\n",
    "#####################################################################################\n",
    "# def duffing(x, t, gamma=0.1, kappa=1, epsilon=5):\n",
    "def duffing(x, t, gamma, kappa, epsilon):\n",
    "\t### Compute dynamics\n",
    "\tdsdt = [x[1], -gamma*x[1] - kappa*x[0] - epsilon*x[0]**3.]\n",
    "\treturn dsdt\n",
    "\n",
    "#####################################################################################\n",
    "##### Parameters \n",
    "#####################################################################################\n",
    "gamma = 0.1\n",
    "kappa = 1.\n",
    "epsilon = 5.\n",
    "poly_order = 3  ##1, x, y, x^2, xy, y^2, x^3, x^2y, xy^2, y^3\n",
    "\n",
    "x_initial = [0., 1.]\n",
    "noise_scale = 0.01 ## constant to adjust the error scale \n",
    "\n",
    "t0, tf = 0, 10  # start and end\n",
    "uniform_dt = 'yes'\n",
    "\n",
    "#####################################################################################\n",
    "##### Make true & noisy data using a dynamic model \n",
    "#####################################################################################\n",
    "DATA = {}\n",
    "\n",
    "##### Time instants \n",
    "if uniform_dt == 'yes':\n",
    "\tdt = 0.001  # time step\n",
    "\tNt = int(np.floor(tf-t0)/dt + 1) #Number of time instances\n",
    "\tt_span = np.linspace(t0, tf, Nt)\n",
    "else:\n",
    "\tNt = 1000 ##the number of time instants\n",
    "\tt_span = np.sort(np.random.uniform(t0, tf, Nt)) ##Choose random time instants \n",
    "\n",
    "dt = np.diff(t_span) ##time step \n",
    "DATA['t'] = t_span\n",
    "nsample = DATA['t'].shape[0]\n",
    "\n",
    "##### Initial Conditions/Values\n",
    "DATA['x:init'] =np.array(x_initial)\n",
    "n_var = len(DATA['x:init'])\n",
    "\n",
    "##### True data from a dynamic model\n",
    "DATA['x:true'] = odeint(lambda x, t:duffing(x, t, gamma, kappa, epsilon), DATA['x:init'], t_span)\n",
    "assert(DATA['x:true'].shape[1] == n_var)\n",
    "\n",
    "##### True dx solutions in time \n",
    "DATA['dx:true'] = np.zeros(DATA['x:true'].shape)\n",
    "for i in range(nsample):\n",
    "\tDATA['dx:true'][i] = duffing(DATA['x:true'][i], t_span[i], gamma, kappa, epsilon)\n",
    "assert(np.sum(abs(DATA['x:true'][:,1] - DATA['dx:true'][:,0])) == 0.)\n",
    "\n",
    "##### Corrupt states by adding noise --> Observation model x_noise(t) = x_true(t) + e(t)\n",
    "Noise = {}\n",
    "Noise['true'] = noise_scale*np.random.randn(Nt, n_var) ## Additive zero-mean white noise (Assumed Gaussian)\n",
    "ti = 0\n",
    "Noise['true'][ti] = 0.  ## Assume there is no noise at the initial time ti=0\n",
    "\n",
    "DATA['x:noisy'] = DATA['x:true'] + Noise['true'] ## Add noise to the true data \n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Train DNN model for Xtrue\n",
    "#####################################################################################\n",
    "import train_dnn_keras\n",
    "reload(train_dnn_keras)\n",
    "from train_dnn_keras import *\n",
    "\n",
    "Ar = {k:Obj() for k in ['Xtrue', 'Coef']}\n",
    "Model = {k:0. for k in ['Xtrue', 'Coef']}\n",
    "Train = {k:{} for k in ['Xtrue', 'Coef']}\n",
    "Min_prev, Max_prev = {k:0. for k in ['Xtrue','Coef']},  {k:0. for k in ['Xtrue','Coef']}\n",
    "Nsample = {}\n",
    "Opt = Obj()\n",
    "\n",
    "\n",
    "mc = 'Xtrue' ###model_case\n",
    "\n",
    "Train[mc]['in'] = DATA['t']\n",
    "Train[mc]['out'] = DATA['x:noisy']\n",
    "Nsample[mc] = Train[mc]['in'].shape\n",
    "\n",
    "hl = 4\n",
    "node = 16\n",
    "batch = 100\n",
    "epoch = 200\n",
    "acti = 'tanh'\n",
    "lr = 1e-3\n",
    "Ar[mc].HiddenLayer, Ar[mc].Nodes, Ar[mc].BatchSize, Ar[mc].Epoch, Ar[mc].Acti_ft, Ar[mc].lr = hl, node, batch, epoch, acti, lr\n",
    "Ar[mc].model_name = mc + '_hl{:d}_node{:d}_batch{:d}_ep{:d}_{:s}.h5'.format(hl, node, batch, epoch, acti)\n",
    "Ar[mc].model_folder = Folder.dnn\n",
    "\n",
    "Opt.train_rate = 0.8\n",
    "Opt.want_normalize = 'no'\n",
    "Opt.Verbose = True\n",
    "\n",
    "# Model[mc], Min_prev[mc], Max_prev[mc] = dnn_train_keras(Train[mc], Ar[mc], Opt)\n",
    "\n",
    "Model[mc] = load_model(Ar[mc].model_folder + Ar[mc].model_name)\n",
    "with open(Ar[mc].model_folder + Ar[mc].model_name.replace('.h5', '.pkl'), 'rb') as f:\n",
    "\t[Min_prev[mc], Max_prev[mc]] = pickle.load(f)\n",
    "\n",
    "# IN, IN_normalized, Label, Pred = {},{},{},{}\n",
    "# IN[mc] = Train['in']\n",
    "# Label[mc] = Train['out']\n",
    "# if Opt.want_normalize == 'yes':\n",
    "# \tIN_normalized[mc] = Normalize_ft(IN[mc], Min_prev[mc]['in'], Max_prev[mc]['in'])\n",
    "# \tPred[mc] = Model[mc].predict(IN_normalized[mc])\n",
    "# \tPred[mc] = Inv_Normalize_ft(Pred[mc], Min_prev[mc]['out'], Max_prev[mc]['out'])\n",
    "# else:\n",
    "# \tPred[mc] = Model[mc].predict(IN[mc])\n",
    "\n",
    "#####################################################################################\n",
    "##### Int(phi(x)) & [X(b) - X(a)] matrices \n",
    "# #####################################################################################\n",
    "mc = 'Coef'\n",
    "pickle_Phi = './data/' + 'Int_Phi.pkl'\n",
    "\n",
    "Nsample[mc] = 1000 ## Nsample for int(phi) implies the number of training samples \n",
    "\n",
    "ab_sample = np.hstack([np.random.uniform(t0, tf, (Nsample[mc],1)), np.random.uniform(t0, tf, (Nsample[mc],1))])\n",
    "\n",
    "Xb_Xa = np.zeros((Nsample[mc], n_var))\n",
    "Int_Phi = [0.]*Nsample[mc]\n",
    "\n",
    "for s in range(Nsample[mc]):\n",
    "\t##### Get samples for (a, b) pair = integration boundary \n",
    "\tint_boundary = ab_sample[s]\n",
    "\ta, b = np.min(int_boundary), np.max(int_boundary)\n",
    "\t\n",
    "\tdiff_ab_tol = (tf - t0)/20.\n",
    "\tif abs(a - b) < diff_ab_tol:\n",
    "\t\ta = np.random.uniform(t0, (t0+tf)/2.-diff_ab_tol/2.)\n",
    "\t\tb = np.random.uniform((t0+tf)/2.+diff_ab_tol/2., tf)\n",
    "\t\tab_sample[s] = np.array([a, b])\n",
    "\n",
    "\t##### Xb_Xa := [X(b) - X(a)] matrix\n",
    "\tif Opt.want_normalize == 'no':\n",
    "\t\tXb_Xa[s] = Model['Xtrue'].predict([b]) - Model['Xtrue'].predict([a])\n",
    "\n",
    "\t##### Calculate Int_Phi := Int_a^b phi(x(t)) dt \n",
    "\tts = np.arange(a, b, 1e-3)\n",
    "\tts[-1] = b\n",
    "\tts_mid = (ts[1:] + ts[:-1])/2.\n",
    "\n",
    "\tx_val = Model['Xtrue'].predict(ts_mid)\n",
    "\tphi_mat = Phi_ft(x_val, poly_order)\n",
    "\n",
    "\tval = phi_mat.T*np.diff(ts)  ### val.T = phi_mat*np.tile(np.diff(ts).reshape(-1,1), [1, P])\n",
    "\tInt_Phi[s] = np.sum(val.T, axis=0)\n",
    "\n",
    "\tprint(\"Int_Phi calculated for #sample = {:d}/{:d}\".format(s, Nsample[mc]))\n",
    "Int_Phi = np.array(Int_Phi)\n",
    "\n",
    "with open(pickle_Phi, 'wb') as f:\n",
    "\tpickle.dump([ab_sample, Xb_Xa, Int_Phi], f)\n",
    "\n",
    "with open(pickle_Phi, 'rb') as f:\n",
    "\t[ab_sample, Xb_Xa, Int_Phi] = pickle.load(f)\n",
    "Nsample[mc] = ab_sample.shape[0]\n",
    "\n",
    "#####################################################################################\n",
    "##### Train \n",
    "#####################################################################################\n",
    "import train_dnn_keras\n",
    "reload(train_dnn_keras)\n",
    "from train_dnn_keras import *\n",
    "\n",
    "Train[mc]['in'] = Int_Phi\n",
    "Train[mc]['out'] = Xb_Xa\n",
    "\n",
    "hl = 0\n",
    "node = 0\n",
    "batch = 10\n",
    "epoch = 300\n",
    "acti = 'tanh'\n",
    "lr = 1e-3\n",
    "Ar[mc].HiddenLayer, Ar[mc].Nodes, Ar[mc].BatchSize, Ar[mc].Epoch, Ar[mc].Acti_ft, Ar[mc].lr = hl, node, batch, epoch, acti, lr\n",
    "Ar[mc].model_name = mc + '_hl{:d}_node{:d}_batch{:d}_ep{:d}_{:s}.h5'.format(hl, node, batch, epoch, acti)\n",
    "Ar[mc].model_folder = Folder.dnn\n",
    "\n",
    "Opt.want_bias = False\n",
    "Opt.train_rate = 0.8\n",
    "Opt.want_normalize = 'no'\n",
    "Opt.Verbose = True\n",
    "\n",
    "# Model[mc], Min_prev[mc], Max_prev[mc] = dnn_train_keras(Train[mc], Ar[mc], Opt)\n",
    "\n",
    "Model[mc] = load_model(Ar[mc].model_folder + Ar[mc].model_name)\n",
    "with open(Ar[mc].model_folder + Ar[mc].model_name.replace('.h5', '.pkl'), 'rb') as f:\n",
    "\t[Min_prev[mc], Max_prev[mc]] = pickle.load(f)\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "##### Performance of Coef model\n",
    "#####################################################################################\n",
    "IN = Train[mc]['in']\n",
    "Label = Train[mc]['out']\n",
    "Pred = Model[mc].predict(IN)\n",
    "print(r2_score(Label[:,0], Pred[:,0]))\n",
    "print(r2_score(Label[:,1], Pred[:,1]))\n",
    "\n",
    "\n",
    "P = Int_Phi.shape[1]\n",
    "Coef = {}\n",
    "Coef['true'] = np.zeros((P, n_var))\n",
    "Coef['true'][2,0] = 1\n",
    "Coef['true'][1,1] = -kappa\n",
    "Coef['true'][2,1] = -gamma\n",
    "Coef['true'][6,1] = -epsilon\n",
    "\n",
    "mc = 'Coef'\n",
    "Coef['dnn'] = Model[mc].get_weights()[0]\n",
    "\n",
    "#####################################################################################\n",
    "ax = {}\n",
    "fig, (ax[0], ax[1]) = plt.subplots(1, 2,figsize=(16,5))\n",
    "for d in range(n_var):\n",
    "\tax[d].plot(Coef['true'][:,d], 'k', lw=1.5)\n",
    "\tax[d].plot(Coef['dnn'][:,d], 'ro')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ##### Calculate approximation for dx from the coefficients achieved\n",
    "Phi = {}\n",
    "method = 'dnn'\n",
    "######\n",
    "dt = 0.001  # time step\n",
    "Nt = int(np.floor(tf-t0)/dt + 1) #Number of time instances\n",
    "t_span = np.linspace(t0, tf, Nt)\n",
    "\n",
    "x = Model['Xtrue'].predict(Data_Reshape(t_span))\n",
    "Phi[method] = Phi_ft(x, poly_order)\n",
    "\n",
    "\n",
    "DATA['dx:' + method] = np.zeros(DATA['dx:true'].shape)\n",
    "for i in range(n_var):\n",
    "\tDATA['dx:' + method][:,i] = np.dot(Phi[method],  Coef[method][:,i])\n",
    "\n",
    "\n",
    "################################################################################\n",
    "ax = {}\n",
    "fig, (ax[0], ax[1]) = plt.subplots(1, 2, figsize=(13,6))\n",
    "\n",
    "for i in range(n_var):\n",
    "\tfor method in ['dnn']:\n",
    "\t\tcc = {'ls':'b', 'bpdn':'r', 'dnn':'g'}[method]\n",
    "\t\tmk = {'ls':'^', 'bpdn':'x', 'dnn':'o'}[method]\n",
    "\t\tax[i].plot(t_span, DATA['dx:'+method][:,i], cc+'-', lw=1.5)\n",
    "\t\tjump = 50\n",
    "\t\tax[i].plot(t_span[::jump], DATA['dx:'+method][:,i][::jump], cc+mk, label=method.upper(), mew=1.5, mfc='none')\n",
    "\tax[i].plot(t_span, DATA['dx:true'][:,i], 'k-', label='True', lw=2)\n",
    "\n",
    "\tax[i].set_xlabel('t')\n",
    "\tax[i].set_ylabel('dx{:d}/dt'.format(i))\n",
    "\tax[i].set_title('Error scale = {:f}'.format(noise_scale))\n",
    "\tax[i].legend(loc='upper left', borderpad=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
